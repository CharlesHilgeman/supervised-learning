{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "cc914b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "e1c76fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Preprocessing: Convert categorical data to numeric ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "c32f77cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "loans_py = pd.read_csv('Resources/2019loans.csv')\n",
    "loans_cy = pd.read_csv('Resources/2020Q1loans.csv')\n",
    "loans_py = loans_py.drop(columns=['Unnamed: 0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "05e2235e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = loans_py.drop('loan_status', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "c5201a7f",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['index', 'loan_amnt', 'int_rate', 'installment', 'annual_inc', 'dti',\n",
      "       'delinq_2yrs', 'inq_last_6mths', 'open_acc', 'pub_rec', 'revol_bal',\n",
      "       'total_acc', 'out_prncp', 'out_prncp_inv', 'total_pymnt',\n",
      "       'total_pymnt_inv', 'total_rec_prncp', 'total_rec_int',\n",
      "       'total_rec_late_fee', 'recoveries', 'collection_recovery_fee',\n",
      "       'last_pymnt_amnt', 'collections_12_mths_ex_med', 'policy_code',\n",
      "       'acc_now_delinq', 'tot_coll_amt', 'tot_cur_bal', 'open_acc_6m',\n",
      "       'open_act_il', 'open_il_12m', 'open_il_24m', 'mths_since_rcnt_il',\n",
      "       'total_bal_il', 'il_util', 'open_rv_12m', 'open_rv_24m', 'max_bal_bc',\n",
      "       'all_util', 'total_rev_hi_lim', 'inq_fi', 'total_cu_tl', 'inq_last_12m',\n",
      "       'acc_open_past_24mths', 'avg_cur_bal', 'bc_open_to_buy', 'bc_util',\n",
      "       'chargeoff_within_12_mths', 'delinq_amnt', 'mo_sin_old_il_acct',\n",
      "       'mo_sin_old_rev_tl_op', 'mo_sin_rcnt_rev_tl_op', 'mo_sin_rcnt_tl',\n",
      "       'mort_acc', 'mths_since_recent_bc', 'mths_since_recent_inq',\n",
      "       'num_accts_ever_120_pd', 'num_actv_bc_tl', 'num_actv_rev_tl',\n",
      "       'num_bc_sats', 'num_bc_tl', 'num_il_tl', 'num_op_rev_tl',\n",
      "       'num_rev_accts', 'num_rev_tl_bal_gt_0', 'num_sats', 'num_tl_120dpd_2m',\n",
      "       'num_tl_30dpd', 'num_tl_90g_dpd_24m', 'num_tl_op_past_12m',\n",
      "       'pct_tl_nvr_dlq', 'percent_bc_gt_75', 'pub_rec_bankruptcies',\n",
      "       'tax_liens', 'tot_hi_cred_lim', 'total_bal_ex_mort', 'total_bc_limit',\n",
      "       'total_il_high_credit_limit', 'home_ownership_ANY',\n",
      "       'home_ownership_MORTGAGE', 'home_ownership_OWN', 'home_ownership_RENT',\n",
      "       'verification_status_Not Verified',\n",
      "       'verification_status_Source Verified', 'verification_status_Verified',\n",
      "       'pymnt_plan_n', 'initial_list_status_f', 'initial_list_status_w',\n",
      "       'application_type_Individual', 'application_type_Joint App',\n",
      "       'hardship_flag_N', 'hardship_flag_Y', 'debt_settlement_flag_N',\n",
      "       'debt_settlement_flag_Y'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>loan_amnt</th>\n",
       "      <th>int_rate</th>\n",
       "      <th>installment</th>\n",
       "      <th>annual_inc</th>\n",
       "      <th>dti</th>\n",
       "      <th>delinq_2yrs</th>\n",
       "      <th>inq_last_6mths</th>\n",
       "      <th>open_acc</th>\n",
       "      <th>pub_rec</th>\n",
       "      <th>...</th>\n",
       "      <th>verification_status_Verified</th>\n",
       "      <th>pymnt_plan_n</th>\n",
       "      <th>initial_list_status_f</th>\n",
       "      <th>initial_list_status_w</th>\n",
       "      <th>application_type_Individual</th>\n",
       "      <th>application_type_Joint App</th>\n",
       "      <th>hardship_flag_N</th>\n",
       "      <th>hardship_flag_Y</th>\n",
       "      <th>debt_settlement_flag_N</th>\n",
       "      <th>debt_settlement_flag_Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>57107</td>\n",
       "      <td>13375.0</td>\n",
       "      <td>0.1797</td>\n",
       "      <td>483.34</td>\n",
       "      <td>223000.0</td>\n",
       "      <td>29.99</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>141451</td>\n",
       "      <td>21000.0</td>\n",
       "      <td>0.1308</td>\n",
       "      <td>478.68</td>\n",
       "      <td>123000.0</td>\n",
       "      <td>11.26</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>321143</td>\n",
       "      <td>20000.0</td>\n",
       "      <td>0.1240</td>\n",
       "      <td>448.95</td>\n",
       "      <td>197000.0</td>\n",
       "      <td>11.28</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11778</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>0.1240</td>\n",
       "      <td>100.22</td>\n",
       "      <td>45000.0</td>\n",
       "      <td>18.08</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>169382</td>\n",
       "      <td>30000.0</td>\n",
       "      <td>0.1612</td>\n",
       "      <td>1056.49</td>\n",
       "      <td>133000.0</td>\n",
       "      <td>27.77</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12175</th>\n",
       "      <td>354912</td>\n",
       "      <td>19975.0</td>\n",
       "      <td>0.2565</td>\n",
       "      <td>801.09</td>\n",
       "      <td>28000.0</td>\n",
       "      <td>28.42</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12176</th>\n",
       "      <td>354944</td>\n",
       "      <td>15000.0</td>\n",
       "      <td>0.1774</td>\n",
       "      <td>540.34</td>\n",
       "      <td>50000.0</td>\n",
       "      <td>23.43</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12177</th>\n",
       "      <td>354973</td>\n",
       "      <td>3600.0</td>\n",
       "      <td>0.1862</td>\n",
       "      <td>131.28</td>\n",
       "      <td>60000.0</td>\n",
       "      <td>28.80</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12178</th>\n",
       "      <td>355002</td>\n",
       "      <td>15000.0</td>\n",
       "      <td>0.0881</td>\n",
       "      <td>475.68</td>\n",
       "      <td>62000.0</td>\n",
       "      <td>11.44</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12179</th>\n",
       "      <td>355307</td>\n",
       "      <td>15000.0</td>\n",
       "      <td>0.1774</td>\n",
       "      <td>540.34</td>\n",
       "      <td>54080.0</td>\n",
       "      <td>21.66</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12180 rows × 93 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        index  loan_amnt  int_rate  installment  annual_inc    dti  \\\n",
       "0       57107    13375.0    0.1797       483.34    223000.0  29.99   \n",
       "1      141451    21000.0    0.1308       478.68    123000.0  11.26   \n",
       "2      321143    20000.0    0.1240       448.95    197000.0  11.28   \n",
       "3       11778     3000.0    0.1240       100.22     45000.0  18.08   \n",
       "4      169382    30000.0    0.1612      1056.49    133000.0  27.77   \n",
       "...       ...        ...       ...          ...         ...    ...   \n",
       "12175  354912    19975.0    0.2565       801.09     28000.0  28.42   \n",
       "12176  354944    15000.0    0.1774       540.34     50000.0  23.43   \n",
       "12177  354973     3600.0    0.1862       131.28     60000.0  28.80   \n",
       "12178  355002    15000.0    0.0881       475.68     62000.0  11.44   \n",
       "12179  355307    15000.0    0.1774       540.34     54080.0  21.66   \n",
       "\n",
       "       delinq_2yrs  inq_last_6mths  open_acc  pub_rec  ...  \\\n",
       "0              0.0             0.0      15.0      0.0  ...   \n",
       "1              2.0             0.0      16.0      0.0  ...   \n",
       "2              0.0             0.0      12.0      0.0  ...   \n",
       "3              0.0             0.0      12.0      1.0  ...   \n",
       "4              0.0             2.0      13.0      0.0  ...   \n",
       "...            ...             ...       ...      ...  ...   \n",
       "12175          0.0             0.0      15.0      0.0  ...   \n",
       "12176          4.0             0.0      16.0      0.0  ...   \n",
       "12177          0.0             1.0      14.0      0.0  ...   \n",
       "12178          0.0             0.0       5.0      0.0  ...   \n",
       "12179          1.0             1.0       5.0      0.0  ...   \n",
       "\n",
       "       verification_status_Verified  pymnt_plan_n  initial_list_status_f  \\\n",
       "0                                 0             1                      0   \n",
       "1                                 0             1                      0   \n",
       "2                                 0             1                      0   \n",
       "3                                 0             1                      0   \n",
       "4                                 0             1                      0   \n",
       "...                             ...           ...                    ...   \n",
       "12175                             0             1                      0   \n",
       "12176                             1             1                      0   \n",
       "12177                             0             1                      0   \n",
       "12178                             0             1                      0   \n",
       "12179                             0             1                      1   \n",
       "\n",
       "       initial_list_status_w  application_type_Individual  \\\n",
       "0                          1                            1   \n",
       "1                          1                            1   \n",
       "2                          1                            1   \n",
       "3                          1                            1   \n",
       "4                          1                            1   \n",
       "...                      ...                          ...   \n",
       "12175                      1                            1   \n",
       "12176                      1                            1   \n",
       "12177                      1                            1   \n",
       "12178                      1                            0   \n",
       "12179                      0                            1   \n",
       "\n",
       "       application_type_Joint App  hardship_flag_N  hardship_flag_Y  \\\n",
       "0                               0                1                0   \n",
       "1                               0                1                0   \n",
       "2                               0                1                0   \n",
       "3                               0                1                0   \n",
       "4                               0                1                0   \n",
       "...                           ...              ...              ...   \n",
       "12175                           0                1                0   \n",
       "12176                           0                1                0   \n",
       "12177                           0                1                0   \n",
       "12178                           1                1                0   \n",
       "12179                           0                1                0   \n",
       "\n",
       "       debt_settlement_flag_N  debt_settlement_flag_Y  \n",
       "0                           1                       0  \n",
       "1                           1                       0  \n",
       "2                           1                       0  \n",
       "3                           1                       0  \n",
       "4                           1                       0  \n",
       "...                       ...                     ...  \n",
       "12175                       1                       0  \n",
       "12176                       1                       0  \n",
       "12177                       1                       0  \n",
       "12178                       1                       0  \n",
       "12179                       1                       0  \n",
       "\n",
       "[12180 rows x 93 columns]"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_dummies = pd.get_dummies(X)\n",
    "print(X_dummies.columns)\n",
    "X_dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "c1131745",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, LabelEncoder\n",
    "\n",
    "y_label = LabelEncoder().fit_transform(loans_py['loan_status'])\n",
    "y_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "b85ea79d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_dummies, y_label, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "a5d1ec97",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler().fit(X_train)\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "695e8d0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.86884072,  0.26219508,  1.12024304, ..., -0.1694586 ,\n",
       "         0.01812499, -0.01812499],\n",
       "       [-0.97142543,  0.75296671,  0.38381548, ..., -0.1694586 ,\n",
       "         0.01812499, -0.01812499],\n",
       "       [-1.77412602,  1.07196827, -1.00362923, ..., -0.1694586 ,\n",
       "         0.01812499, -0.01812499],\n",
       "       ...,\n",
       "       [ 0.5308302 , -0.52303953,  2.79049113, ..., -0.1694586 ,\n",
       "         0.01812499, -0.01812499],\n",
       "       [ 0.78356135,  0.26219508,  2.79049113, ..., -0.1694586 ,\n",
       "         0.01812499, -0.01812499],\n",
       "       [ 1.02208108, -0.71934818,  0.69129297, ..., -0.1694586 ,\n",
       "         0.01812499, -0.01812499]])"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "a2fa0937",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k: 1 - Training|Testing Scores: 1.000|0.574\n",
      "k: 1001 - Training|Testing Scores: 1.000|0.574\n",
      "k: 2001 - Training|Testing Scores: 1.000|0.574\n",
      "k: 3001 - Training|Testing Scores: 1.000|0.574\n",
      "k: 4001 - Training|Testing Scores: 1.000|0.574\n",
      "k: 5001 - Training|Testing Scores: 1.000|0.574\n",
      "k: 6001 - Training|Testing Scores: 1.000|0.574\n",
      "k: 7001 - Training|Testing Scores: 1.000|0.574\n",
      "k: 8001 - Training|Testing Scores: 1.000|0.574\n",
      "k: 9001 - Training|Testing Scores: 1.000|0.574\n",
      "k: 10001 - Training|Testing Scores: 1.000|0.574\n",
      "k: 11001 - Training|Testing Scores: 1.000|0.574\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "train_scores = []\n",
    "test_scores = []\n",
    "for k in range(1,12000,1000):\n",
    "    knn = KNeighborsClassifier(n_neighbors=1)\n",
    "    knn.fit(X_train_scaled, y_train)\n",
    "    train_score = knn.score(X_train_scaled, y_train)\n",
    "    test_score = knn.score(X_test_scaled, y_test)\n",
    "    train_scores.append(train_score)\n",
    "    test_scores.append(test_score)\n",
    "    print(f\"k: {k} - Training|Testing Scores: {train_score:.3f}|{test_score:.3f}\")\n",
    "    \n",
    "plt.plot(range(1,12000,1000), train_scores, c='red')\n",
    "plt.plot(range(1,12000,1000), test_scores, c='blue')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "e4fcff36",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Fit a LogisticRegression model and RandomForestClassifier model ###"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95bb3d4f",
   "metadata": {},
   "source": [
    "Logistic Regression vs Random Forest Classifier:\n",
    "\n",
    "I think the Random Forest Classifier will perform better in this situation than Logistic Regression will. From what we've learned in class, over-fitting the data is a real possibility so if a training set with a particular amount of noise will cause the regression to sacrifice its testing score to \"better\" fit the training data. In this case, I think the Random Forest Classifier will likely ignore some of those to achieve a more accurate model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "2d2b4415",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Logistic Regression\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_dummies, y_label, random_state=1)\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "classifier = LogisticRegression()\n",
    "classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "458a9cfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Charles Hilgeman\\anaconda\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "a57a31b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression\n",
      "Training Score: 0.6553913519430761\n",
      "Testing Score: 0.6469622331691297\n"
     ]
    }
   ],
   "source": [
    "print(\"Logistic Regression\")\n",
    "print(f\"Training Score: {classifier.score(X_train, y_train)}\")\n",
    "print(f\"Testing Score: {classifier.score(X_test, y_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "35352785",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Random Forest Classifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_dummies, y_label, random_state=1)\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "cf5e3c6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Classifier\n",
      "Training Score: 1.0\n",
      "Testing Score: 0.7904761904761904\n"
     ]
    }
   ],
   "source": [
    "clf = RandomForestClassifier(random_state=1, n_estimators=500).fit(X_train_scaled, y_train)\n",
    "print(\"Random Forest Classifier\")\n",
    "print(f\"Training Score: {clf.score(X_train_scaled, y_train)}\")\n",
    "print(f\"Testing Score: {clf.score(X_test_scaled, y_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "5fca49bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Revisit the Preprocessing: Scale the data ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "a7f468ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 93 artists>"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "features = clf.feature_importances_\n",
    "plt.bar(x = range(len(features)), height=features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "d5485524",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True,  True,  True,  True, False, False, False,\n",
       "       False,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True, False, False,  True, False, False, False, False,  True,\n",
       "       False, False, False, False,  True,  True,  True, False, False,\n",
       "        True,  True,  True, False, False, False, False,  True,  True,\n",
       "        True, False, False,  True,  True,  True, False, False,  True,\n",
       "        True, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False,  True,  True,  True,  True, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False])"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "sel = SelectFromModel(clf)\n",
    "sel.fit(X_train_scaled, y_train)\n",
    "sel.get_support()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "12983c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_selected_train, X_selected_test, y_train, y_test = train_test_split(sel.transform(X_train_scaled), y_train, random_state=1)\n",
    "scaler = StandardScaler().fit(X_selected_train)\n",
    "X_selected_train_scaled = scaler.transform(X_selected_train)\n",
    "X_selected_test_scaled = scaler.transform(X_selected_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "440a9294",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression\n",
      "Training Score: 0.7066121734053423\n",
      "Testing Score: 0.6900175131348512\n"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegression()\n",
    "clf.fit(X_selected_train_scaled, y_train)\n",
    "print(\"Logistic Regression\")\n",
    "print(f\"Training Score: {clf.score(X_selected_train_scaled, y_train)}\")\n",
    "print(f\"Testing Score: {clf.score(X_selected_test_scaled, y_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "ed25eeda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Classifier\n",
      "Training Score: 1.0\n",
      "Testing Score: 0.8025394045534151\n"
     ]
    }
   ],
   "source": [
    "clf = RandomForestClassifier(random_state=1, n_estimators=500).fit(X_selected_train_scaled, y_train)\n",
    "print(\"Random Forest Classifier\")\n",
    "print(f\"Training Score: {clf.score(X_selected_train_scaled, y_train)}\")\n",
    "print(f\"Testing Score: {clf.score(X_selected_test_scaled, y_test)}\")"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
